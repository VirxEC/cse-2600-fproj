{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boost/bcpm\n",
    "# boost/amount_stolen\n",
    "# movement/count_powerslide\n",
    "# movement/avg_speed\n",
    "# movement/percent_ground\n",
    "# movement/percent_high_air\n",
    "# positioning/avg_distance_to_mates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "rank_data: dict[str, pd.DataFrame] = {}\n",
    "include_columns = [\n",
    "    \"positioning/goals_against_while_last_defender\",\n",
    "    \"movement/percent_high_air\",\n",
    "    \"movement/time_high_air\",\n",
    "    \"positioning/avg_distance_to_mates\",\n",
    "    \"movement/count_powerslide\",\n",
    "    \"movement/percent_supersonic_speed\",\n",
    "    \"movement/avg_powerslide_duration\",\n",
    "    \"movement/avg_speed\",\n",
    "    \"movement/percent_ground\",\n",
    "    \"movement/avg_speed_percentage\",\n",
    "    \"boost/bcpm\",\n",
    "    \"boost/amount_collected_small\",\n",
    "    \"movement/time_powerslide\",\n",
    "    \"boost/amount_used_while_supersonic\",\n",
    "    \"boost/bpm\",\n",
    "    \"positioning/percent_closest_to_ball\",\n",
    "    \"positioning/percent_neutral_third\",\n",
    "    \"boost/count_collected_small\",\n",
    "    \"positioning/avg_distance_to_ball_no_possession\",\n",
    "    \"movement/time_supersonic_speed\",\n",
    "    \"movement/percent_boost_speed\",\n",
    "    \"movement/percent_slow_speed\",\n",
    "    \"positioning/avg_distance_to_ball\",\n",
    "    \"positioning/avg_distance_to_ball_possession\",\n",
    "    \"movement/percent_low_air\",\n",
    "    \"positioning/percent_most_forward\",\n",
    "    \"boost/percent_boost_50_75\",\n",
    "    \"positioning/percent_farthest_from_ball\",\n",
    "    \"boost/percent_zero_boost\",\n",
    "    \"boost/avg_amount\",\n",
    "    \"boost/percent_boost_0_25\",\n",
    "    \"boost/percent_boost_25_50\",\n",
    "    \"core/score\",\n",
    "    \"boost/time_zero_boost\",\n",
    "    \"positioning/time_closest_to_ball\",\n",
    "    \"boost/percent_full_boost\",\n",
    "    \"boost/amount_overfill\",\n",
    "    \"positioning/percent_most_back\",\n",
    "    \"movement/time_ground\",\n",
    "    \"boost/percent_boost_75_100\",\n",
    "    \"boost/time_boost_50_75\",\n",
    "    \"boost/time_full_boost\",\n",
    "    \"positioning/time_most_forward\",\n",
    "    \"boost/time_boost_25_50\",\n",
    "    \"boost/time_boost_0_25\",\n",
    "    \"positioning/percent_behind_ball\",\n",
    "    \"positioning/percent_infront_ball\",\n",
    "    \"boost/amount_stolen_small\",\n",
    "    \"boost/time_boost_75_100\",\n",
    "    \"boost/amount_stolen\",\n",
    "    \"positioning/time_infront_ball\",\n",
    "    \"movement/time_boost_speed\",\n",
    "    \"movement/time_slow_speed\",\n",
    "    \"positioning/time_farthest_from_ball\",\n",
    "    \"positioning/time_neutral_third\",\n",
    "    \"boost/amount_collected_big\",\n",
    "    \"positioning/percent_offensive_third\",\n",
    "    \"boost/amount_collected\",\n",
    "    \"positioning/time_offensive_third\",\n",
    "    \"positioning/time_most_back\",\n",
    "    \"positioning/percent_defensive_third\",\n",
    "    \"movement/time_low_air\",\n",
    "    \"boost/amount_overfill_stolen\",\n",
    "]\n",
    "# include_columns = [\n",
    "#     \"positioning/goals_against_while_last_defender\",\n",
    "#     \"movement/percent_high_air\",\n",
    "#     \"movement/time_high_air\",\n",
    "#     \"positioning/avg_distance_to_mates\",\n",
    "#     \"movement/percent_supersonic_speed\",\n",
    "#     \"movement/count_powerslide\",\n",
    "#     \"movement/avg_powerslide_duration\",\n",
    "#     \"movement/avg_speed_percentage\",\n",
    "#     \"movement/percent_ground\",\n",
    "#     \"movement/avg_speed\",\n",
    "#     \"boost/bcpm\",\n",
    "#     \"boost/amount_collected_small\",\n",
    "#     \"positioning/percent_neutral_third\",\n",
    "#     \"boost/bpm\",\n",
    "#     \"boost/amount_used_while_supersonic\",\n",
    "#     \"positioning/percent_closest_to_ball\",\n",
    "#     \"movement/time_powerslide\",\n",
    "#     \"movement/time_supersonic_speed\",\n",
    "#     \"boost/count_collected_small\",\n",
    "# ]\n",
    "\n",
    "root_folder = Path(\"./\") if Path(\"./rank_samples\").exists() else Path(\"/project\")\n",
    "for file in root_folder.glob(\"rank_samples/*.csv\"):\n",
    "    if \"bronze\" in file.stem:\n",
    "        continue\n",
    "\n",
    "    rank_data[file.stem] = pd.read_csv(file)\n",
    "    # only include the above listed columns, e.x. boost/bcpm\n",
    "    rank_data[file.stem] = rank_data[file.stem][include_columns]\n",
    "\n",
    "# create a mapping from rank to number\n",
    "rank_to_number = {\n",
    "    # \"bronze-1\": 1,\n",
    "    # \"bronze-2\": 2,\n",
    "    # \"bronze-3\": 3,\n",
    "    # \"silver-1\": 4,\n",
    "    # \"silver-2\": 5,\n",
    "    \"silver-3\": 6,\n",
    "    \"gold-1\": 7,\n",
    "    \"gold-2\": 8,\n",
    "    \"gold-3\": 9,\n",
    "    \"platinum-1\": 10,\n",
    "    \"platinum-2\": 11,\n",
    "    \"platinum-3\": 12,\n",
    "    \"diamond-1\": 13,\n",
    "    \"diamond-2\": 14,\n",
    "    \"diamond-3\": 15,\n",
    "    \"champion-1\": 16,\n",
    "    \"champion-2\": 17,\n",
    "    \"champion-3\": 18,\n",
    "    \"grand-champion-1\": 19,\n",
    "    \"grand-champion-2\": 20,\n",
    "    \"grand-champion-3\": 21,\n",
    "}\n",
    "\n",
    "# randomly sample at most 75000 // 21 rows from each rank\n",
    "# for key, df in rank_data.items():\n",
    "#     rank_data[key] = df.sample(min(400000 // len(rank_to_number.keys()), len(df)))\n",
    "\n",
    "# combine the data, add the key as a column\n",
    "combined_data = pd.concat([df.assign(rank=key) for key, df in rank_data.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"rank\" is something like 'bronze-1', 'bronze-2', 'silver-1', etc.\n",
    "# we need to convert this to a number so we can use it in our models\n",
    "\n",
    "# convert the rank column to a number, dropping if it doesn't exist in the mapping\n",
    "combined_data[\"rank\"] = combined_data[\"rank\"].map(rank_to_number)\n",
    "# combined_data = combined_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in NaNs with the mean of the 'rank' column\n",
    "\n",
    "# calculate the mean of each column for each rank\n",
    "mean_data = combined_data.groupby(\"rank\").mean()\n",
    "\n",
    "# fill in the NaNs with the mean of the rank\n",
    "for rank in mean_data.index:\n",
    "    combined_data.loc[combined_data[\"rank\"] == rank] = combined_data.loc[combined_data[\"rank\"] == rank].fillna(mean_data.loc[rank])\n",
    "\n",
    "combined_data = combined_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split, rank is the y\n",
    "X = combined_data.drop(columns=[\"rank\"])\n",
    "y = combined_data[\"rank\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486968, 63) (486968,) (121742, 63) (121742,)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the data\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 estimators had an error of 41.56%; MSE: 3.2545054295148756\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "# num_estimators = list(range(350, 500, 50))\n",
    "num_estimators = [700]\n",
    "for i in num_estimators:\n",
    "    print(f\"Training with {i} estimators\", end=\"\")\n",
    "    model = RandomForestClassifier(n_estimators=i, n_jobs=24)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    errors.append(1 - model.score(X_test, y_test))\n",
    "    print(f\"\\r{i} estimators had an error of {errors[-1]*100:.2f}%; \", end=\"\")\n",
    "\n",
    "    mse = np.mean((model.predict(X_test) - y_test) ** 2)\n",
    "    print(f\"MSE: {mse}\")\n",
    "\n",
    "    # save the model to a file via pickle\n",
    "    joblib.dump(model, f\"model-{i}.joblib\")\n",
    "\n",
    "# plt.plot(num_estimators, errors)\n",
    "# plt.xlabel(\"Number of estimators\")\n",
    "# plt.ylabel(\"Error rate\")\n",
    "# plt.show()\n",
    "\n",
    "least_error_idx = np.argmin(errors)\n",
    "least_error = errors[least_error_idx]\n",
    "least_error_estimators = num_estimators[least_error_idx]\n",
    "print(f\"The least error rate is {least_error:.2f} with {least_error_estimators} estimators.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
